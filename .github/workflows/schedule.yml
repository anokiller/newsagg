name: Run Tech News Aggregator

on:
  schedule:
    - cron: '0 */8 * * *'  # Runs every 6 hours
  workflow_dispatch:  # Allows manual triggering in the Actions tab

jobs:
  run-technews:
    runs-on: ubuntu-latest

    steps:
      # 1) Checkout your repository
      - name: Check out code
        uses: actions/checkout@v3

      # 2) Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'  # Adjust as needed

      # 3) Cache pip dependencies (optional but recommended)
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # 4) Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 5) Ensure processed_urls.json exists before running the script
      - name: Ensure processed_urls.json exists
        run: |
          if [ ! -f processed_urls.json ]; then
            echo "processed_urls.json not found, creating an empty one."
            echo "{}" > processed_urls.json
          fi
          
      # 6) Run technewsagg.py
      - name: Run Tech News Aggregator
        env:
          BOT_API_TOKEN: ${{ secrets.BOT_API_TOKEN }}
          CHAT_ID: ${{ secrets.CHAT_ID }}
        run: |
          python technewsagg.py

      - name: Commit and Push Updated processed_urls.json
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add processed_urls.json
          git commit -m "Update processed URLs" || echo "No changes to commit"
          git push https://x-access-token:${GITHUB_TOKEN}@github.com/anokiller/newsagg.git main
