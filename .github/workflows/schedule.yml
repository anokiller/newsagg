name: Run News Summarizer

on:
  schedule:
    - cron: '0 */8 * * *'  # Runs every 6 hours
  workflow_dispatch:  # Allow manual triggering

jobs:
  run-summarizer:
    runs-on: ubuntu-latest

    steps:
      # 1) Checkout your repository
      - name: Check out code
        uses: actions/checkout@v3

      # 2) Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # 3) Download existing processed URLs artifact (if any)
      #    If this artifact doesn't exist yet, this step won't fail your workflow
      - name: Download processed URLs artifact
        uses: actions/download-artifact@v3
        with:
          name: processed-urls
          path: .
        continue-on-error: true

      # 4) Cache pip dependencies (optional but recommended)
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # 5) Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 6) Run your summarizer script
      - name: Run Summarizer
        env:
          BOT_API_TOKEN: ${{ secrets.BOT_API_TOKEN }}
          CHAT_ID: ${{ secrets.CHAT_ID }}
        run: |
          # If your script needs a path argument:
          # python newsagg.py --processed-urls ./processed_urls.json
          
          # Otherwise, if your script already writes to processed_urls.json by default:
          python newsagg.py

      # 7) Upload the updated processed_urls.json as an artifact
      - name: Upload processed URLs artifact
        uses: actions/upload-artifact@v3
        with:
          name: processed-urls
          path: ./processed_urls.json
